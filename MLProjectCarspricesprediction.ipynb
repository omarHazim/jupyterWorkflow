{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "raw_mimetype": "text/markdown",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## ML Project: Predicting Car Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 15,
        "hidden": false,
        "row": 22,
        "width": 4
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import front end lib\n",
    "import pandas as pd\n",
    "import requests\n",
    "from collections import namedtuple\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Building wedgets to make interactive function\n",
    "import ipywidgets as wg\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "#the lib below to make pandas DF shows pretty tabels\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# Run IPython kernal as HTML slidshow\n",
    "#!jupyter nbconvert  MLProjectCarspricesprediction.ipynb   --to slides --post serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset download and preperations process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "lang": "en",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Download the webpage to extract the columns name and dataset dataframe\n",
    "def download_pars_dataset(url_cols, url_dataset):\n",
    "    \"\"\"\n",
    "    Downloading and parsing columnes /dataset\n",
    "    Inputs:\n",
    "    __________________\n",
    "     - url_cols: str\n",
    "        URL of columns data\n",
    "     - url_dataset: str\n",
    "        URL of dataset\n",
    "    Outputs:\n",
    "    __________________\n",
    "     - columns name with final dataset as dataframe \n",
    "    \"\"\"\n",
    "    #Downloading and parsing columns\n",
    "    r_cols = requests.get(url_cols)\n",
    "    data_text = r_cols.text\n",
    "    data_text_lines = data_text.splitlines()\n",
    "    cols = []\n",
    "    for line in data_text_lines:\n",
    "        pattern0 = r\"\\s\\d+. ([a-zA-Z]+).*:\"\n",
    "        if re.search(pattern0, line):\n",
    "            cols.append(line)\n",
    "    col_nme = [re.split(':?', entry, 3) for entry in cols]\n",
    "\n",
    "    # Final column names\n",
    "    pattern1 = r\"([a-zA-Z]+)\"\n",
    "    cols_nme = [re.search(pattern1, col[0]).group() for col in col_nme]\n",
    "\n",
    "    #Downloadung and parsing dataset\n",
    "    r_dataset = requests.get(url_dataset)\n",
    "    dataset_text = r_dataset.text.split('\\n')\n",
    "    data_set_cars = [item for item in dataset_text]\n",
    "    cars_dataset = pd.DataFrame(\n",
    "        [x.split(\",\") for x in data_set_cars], columns=cols_nme)\n",
    "    return cars_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 29,
        "hidden": false,
        "row": 86,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "lang": "fr"
   },
   "source": [
    "## Téléchargez la page Web pour extraire le nom des colonnes et l'ensemble de données du dataset\n",
    "def download _pars_ ensemble de données (url _cols, url_ ensemble de données):\n",
    "    \"\" \"\n",
    "    Téléchargement et analyse de columnes / dataset\n",
    "    Contributions:\n",
    "    ____ ____ ____ ____ __- url_cols: str\n",
    "        URL des données de colonnes\n",
    "     - url_dataset: str\n",
    "        URL de l'ensemble de données\n",
    "    Les sorties:__ ____ ____ ____ ____\n",
    "     - nom des colonnes avec l'ensemble de données final en tant que données\n",
    "    \"\" \"\n",
    "    #Télécharger et analyser les colonnes\n",
    "    r _cols = requests.get (url_ cols)\n",
    "    données _text = r_ cols.text\n",
    "    data _text_ lignes = données _text.splitlines ()\n",
    "    cols = []\n",
    "    pour les lignes de données_ text _:\n",
    "        pattern0 = r \"\\ s \\ d +. ([a-zA-Z] +). *:\"\n",
    "        si re.search (motif0, ligne):\n",
    "            cols.append (ligne)\n",
    "    col_ nme = [re.split (':?', entry, 3) pour l'entrée dans cols]\n",
    "\n",
    "    # Noms de colonnes finaux\n",
    "    pattern1 = r \"([a-zA-Z] +)\"\n",
    "    cols _nme = [re.search (pattern1, col [0]). group () pour col dans col_ nme]\n",
    "\n",
    "    #Downloadung et l'analyse de données\n",
    "    r _dataset = requests.get (url_ ensemble de données)\n",
    "    dataset _text = r_ dataset.text.split ('\\ n')\n",
    "    data _set_ cars = [élément de l'élément dans le jeu de données _texte]\n",
    "    cars_ dataset = pd.DataFrame (\n",
    "        [x.split (\",\") pour x dans les données _set_ cars], columns = cols _nme)\n",
    "    retour des voitures_ ensemble de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 8,
        "hidden": false,
        "row": 14,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omar/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "# Setting up a numeric features dataframe\n",
    "## Parsing \"imports-85.names\" to find the column names for the dataset\n",
    "url_cols = \"http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.names\"\n",
    "url_dataset = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "\n",
    "# Download the dataset and convert it to dataframe\n",
    "cars_dataset_numeric_features = download_pars_dataset(url_cols=url_cols, url_dataset=url_dataset)\n",
    "cars_dataset_numeric_features = cars_dataset_numeric_features.apply(lambda x: pd.to_numeric(x,errors='coerce'))    \n",
    "\n",
    "# Decide which cols. have certain Nan values (e.g. > 100) to be reduced from the original dataframet\n",
    "new = cars_dataset_numeric_features.isnull().apply(sum, axis=0) > 100 \n",
    "cars_new_numeric_dataset = cars_dataset_numeric_features.drop(cars_dataset_numeric_features.loc[:,new], axis=1)\n",
    "cars_new_numeric_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 12,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Detremine missing values in cols with max number of NaN among rows\n",
    "missing_values_cars_df = cars_new_numeric_dataset.isnull().apply(sum, axis=1)\n",
    "\n",
    "# max number of NaN presnets in the data across the cols\n",
    "max_num_nan_rows = missing_values_cars_df.value_counts() \n",
    "\n",
    "# max number of NaN among rows is 15\n",
    "max_num_nan_rows.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 8,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop row across set of cols that have all NaN values \n",
    "row_max_nan = missing_values_cars_df[missing_values_cars_df.apply(\n",
    "    lambda x: x == max(max_num_nan_rows.index))]\n",
    "cars_df_after_removing_nan_max = cars_new_numeric_dataset.drop(list(row_max_nan.index))\n",
    "\n",
    "# Impute missing values \"NaN\" using mean values across cols\n",
    "## Note: there is a class called \"imputer\" within \"from sklearn.preprocessing \n",
    "##import Imputer\" which can handel missing values \"other than NaN\"\n",
    "mean_vla_cols = cars_df_after_removing_nan_max.apply(lambda x: np.mean(x), axis=0)\n",
    "cars_df_with_mean = cars_df_after_removing_nan_max.replace(np.nan, mean_vla_cols)\n",
    "cars_df_with_mean.head()\n",
    "\n",
    "## Imputing missing values: Simulating distribution method\n",
    "#mean_df_nan = cars_df_after_removing_nan_max['price'].mean()\n",
    "#std_df_nan = cars_df_after_removing_nan_max['price'].std()\n",
    "#cars_new_sim_df = pd.DataFrame(np.random.normal(mean_df_nan, std_df_nan, \n",
    "#len(cars_df_after_removing_nan_max['price'])))\n",
    "#nan_label = cars_new_sim_df[cars_df_after_removing_nan_max['price'].isnull()]\n",
    "#cars_df_after_removing_nan_max['price'].loc[list(nan_label[0].index)]=nan_label[0]\n",
    "#cars_df_after_removing_nan_max['price'].head(10)\n",
    "#nan_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 8,
        "hidden": false,
        "row": 43,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize cars dataset\n",
    "cars_normalized_df = (cars_df_with_mean-cars_df_with_mean.mean()) / (cars_df_with_mean.max() - cars_df_with_mean.min())\n",
    "cars_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building univariate k-nearest neighbors models: Predicting car prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# univariate k-nearest neighbors \n",
    "\n",
    "## Building univariate k-nearest neighbors function\n",
    "def knn_train_test(feature_nme, target_nme, df, perc_fig, n_neigh):\n",
    "    \"\"\"\n",
    "    Univariate KNN model\n",
    "    Inputs:\n",
    "    _____________\n",
    "     - feature_nme: str\n",
    "         a col. that used as a feature input\n",
    "     - target_nme: str\n",
    "         a col. to predict \n",
    "     - df: dataframe\n",
    "         dataframe input\n",
    "     - perc_fig: float\n",
    "         a '%' used to set up training/testing samples\n",
    "     Outputs:\n",
    "     ____________\n",
    "     - list of average RMSE for Knn model \n",
    "    \"\"\"\n",
    "    # Set up training /testing set\n",
    "    perc_train_test = round(len(df[feature_nme])* perc_fig)\n",
    "    training_set = df.iloc[:perc_train_test]\n",
    "    testing_set = df.iloc[perc_train_test:]\n",
    "    \n",
    "    # Set up univariate k-nearest neighbors models\n",
    "    knn = KNeighborsRegressor(n_neighbors = n_neigh, algorithm='brute')\n",
    "    fit = knn.fit(training_set[feature_nme], training_set[target_nme])\n",
    "    predicts = knn.predict(testing_set[feature_nme])\n",
    "    RMSE = np.sqrt(mean_squared_error(testing_set[target_nme], predicts))\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Applying univariate k-nearest neighbors function to cars \n",
    "#datatframe and find the best fit\n",
    "\n",
    "## Link a float slide widget to univariate Knn model\n",
    "def knn_model(perc_fig, n_neigh):\n",
    "    \"\"\"\n",
    "    apply knn func \"knn_train_test\" to find best univariate model\n",
    "    Inputs:\n",
    "    _____________\n",
    "     - perc_fig: float\n",
    "         a % to use for setting up training/testing data sebsets\n",
    "     - n_neigh: int\n",
    "         n_neigh. value to set up Knn model\n",
    "    Outputs:\n",
    "    ____________\n",
    "     - plot of average RMSE for n random iteration/hyperprameter\n",
    "    \"\"\"\n",
    "    ## Applying \"knn_train_test\" to find best univariate Knn model\n",
    "    knn_model_rmse = {}\n",
    "    for col in cars_normalized_df.columns:\n",
    "        if col != 'price':\n",
    "            feature_model = knn_train_test([col],['price'], cars_normalized_df, perc_fig, n_neigh)\n",
    "            knn_model_rmse[col] = feature_model\n",
    "    ## Plotting RMSE of univariate Knn model\n",
    "    ax.clear()\n",
    "    ax.bar(knn_model_rmse.keys(),knn_model_rmse.values())\n",
    "    frm_color = 'white'\n",
    "    ax.tick_params(color=frm_color, labelcolor=frm_color)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(frm_color)\n",
    "    plt.suptitle('Univariate k-nearest neighbors RMSE', color=frm_color)\n",
    "    plt.xticks(rotation=40)\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 6,
        "height": 6,
        "hidden": false,
        "row": 47,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## High-resolution plot outputs for Retina notebooks\n",
    "#%matplotlib nbagg\n",
    "#%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "fig, ax  = plt.subplots(1, figsize=(13,5))\n",
    "## manupolate dataframe \n",
    "#df.resample('W').sum().plot \n",
    "\n",
    "# Set up a widget to manipulate RMSE by changing training/testing percentage of df\n",
    "perc_training = wg.FloatSlider(min=0.05,max=1,step=.01,description='% of training dataset:')\n",
    "n_ne = wg.IntSlider(min=2,max=10,step=1,description='n_neighbors parameter:')\n",
    "wg.interactive(knn_model, perc_fig=perc_training, n_neigh=n_ne)\n",
    "#knn_model(.8, 5)\n",
    "#display(perc_training, n_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 57,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key take away from the univariate Knn model\n",
    " - The univariat Knn model applies one feature each step at a time to predict the \"target\" car price\n",
    " - By changing the widgets sliders, we can view the best univariate Knn model (i.e with lowest RMSE value compared to other univariate Knn models) as follows;\n",
    "- at 50-50 training/testing with default n_neighbor parameter (k = 5), the best univariate model  is with a \"height\" independent var, while setting training/testing with default n_neighbor parameter (k = 5) at 80-20, the best univariate model revealed with a \"compression\" independent var.\n",
    "- Increasing n_neighbor parameter doesn't countribute to the performance \n",
    "- Having build a slide widgets linked to the univariate Knn model gives another perspective of the best univarite Knn model with lowest RMSE testing procedures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 70,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building multivariate k-nearest neighbors models: Predicting car prices   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Multivariate k-nearest neighbors \n",
    "\n",
    "## Building Multivariate k-nearest neighbors function\n",
    "def multi_knn_train_test(df,features_cols, target_col,prec_train, n_neighbor):\n",
    "    \"\"\"\n",
    "    Multivariate KNN model\n",
    "     - feature_nme: a col. that used as a feature input\n",
    "     - target_nme: a col. to predict \n",
    "     - df: dataframe input\n",
    "     - perc_fig: a '%' used to set up training/testing samples\n",
    "    \"\"\"\n",
    "    # Set up training /testing set\n",
    "    #features_cols = [col for idx, col in enumerate(list(df.columns)) if col != target_col]\n",
    "    perc_train_test = round(len(df[features_cols])* prec_train)\n",
    "    training_set = df.iloc[:perc_train_test]\n",
    "    testing_set = df.iloc[perc_train_test:]\n",
    "    \n",
    "    # Set up Multivariate k-nearest neighbors models\n",
    "    knn = KNeighborsRegressor(n_neighbors = n_neighbor, algorithm='brute')\n",
    "    fit = knn.fit(training_set[features_cols], training_set[target_col])\n",
    "    predicts = knn.predict(testing_set[features_cols])\n",
    "    RMSE = np.sqrt(mean_squared_error(testing_set[target_col], predicts))\n",
    "    #MAE = sum(np.abs(predicts - testing_set[target_nme])) / len(testing_set)\n",
    "    #RMSE_prop = RMSE/MAE\n",
    "    #results = {'RMSE':RMSE, 'MAE':MAE, 'RMSE proportion':RMSE_prop}\n",
    "    return RMSE\n",
    "\n",
    "## Link a float slide widget to multivariate Knn model\n",
    "def multi_knn_model(n_neigh, perc_fig, rand_n):\n",
    "    \"\"\"\n",
    "    apply knn func \"knn_train_test\" to find best multivariate model for \n",
    "    each random set of features\n",
    "    Inputs:\n",
    "    ________________\n",
    "       - n_neigh: int\n",
    "           n_neighbor parameter in Knn func.\n",
    "       - perc_fig: float\n",
    "           % of dataframe splitting up training and testing set\n",
    "       - rand_n: float\n",
    "           random 'n' number iterations tp run Knn model\n",
    "   Outputs:\n",
    "   _________________\n",
    "       - list of average RMSE\n",
    "    \"\"\"\n",
    "    ## create random, nonrepetitive pairs from a list of columns\n",
    "    #for iteration in range(rand_n):\n",
    "        #multi_col_rnd_selection = {idx:np.random.choice(cars_normalized_df.columns, idx, replace=False) for idx, col in enumerate(cars_normalized_df.columns)}\n",
    "        #multi_rnd_selection_excpt_0_1 = [item for item in multi_col_rnd_selection.values() if len(item) > 1]\n",
    "    ###################### New set up#######################   \n",
    "    result_1 = {}\n",
    "    features_cols_lst = [col for idx, col in enumerate(list(cars_normalized_df.columns)) if col != 'price']\n",
    "    for idx, col in enumerate(features_cols_lst):\n",
    "            x = np.random.choice(features_cols_lst, idx, replace=False)\n",
    "            result_1[idx] = x\n",
    "    res1 = [item for item in result_1.values() if len(item) > 1]\n",
    "            \n",
    "    ## Applying \"knn_train_test\" to find best multivariate Knn model based on random feature selction \n",
    "    ## Iterating thru each multi-col selection \n",
    "    RMSE_total = {}\n",
    "    for i in range(rand_n):\n",
    "        RMSE_RES = {}\n",
    "        for idx,pair in enumerate(res1):\n",
    "            RMSE_RES[len(pair)] = multi_knn_train_test(cars_normalized_df ,pair ,'price',perc_fig ,n_neigh)\n",
    "        RMSE_total[i] = RMSE_RES\n",
    "    lst_rmse = []    \n",
    "    for i_1 in range(len(RMSE_total.keys())):\n",
    "        x = list(list(RMSE_total.values())[i_1].values())\n",
    "        lst_rmse.append(x)\n",
    "    avrg_rmse = [sum(n)/len(n) for n in list(zip(*lst_rmse))]   \n",
    "    avrg_rmse_plt_df = pd.DataFrame(avrg_rmse, columns=['Avrg RMSE'] ,index=list(list(RMSE_total.values())[0]))\n",
    "    \n",
    "    ## Plotting RMSE of multivariate Knn model\n",
    "    #ax.clear()\n",
    "    #avrg_rmse_plt_df.plot(kind='bar', title='AVRG RMSE for N random iteration')\n",
    "\n",
    "    ## Plotting RMSE of multivariate Knn model\n",
    "    ax.clear()\n",
    "    ax.bar(avrg_rmse_plt_df.index,list(avrg_rmse_plt_df['Avrg RMSE']))\n",
    "    frm_color = 'white'\n",
    "    ax.tick_params(color=frm_color, labelcolor=frm_color)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(frm_color)\n",
    "    plt.style.use('seaborn')\n",
    "    plt.title('Avrg RMSE for Knn model with n random Iteration', color='white')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 2,
        "hidden": false,
        "row": 41,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Applying multivariate k-nearest neighbors function to cars datatframe and find the best fit\n",
    "# Set up a widget to manipulate RMSE by changing training/testing percentage and n_neighbors parameter  of df \n",
    "%matplotlib nbagg\n",
    "#matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "fig, ax  = plt.subplots(1, figsize=(15,5))\n",
    "\n",
    "## Link and apply Knn model to a plain plot\n",
    "#multi_knn_model(5, 0.8, 100)\n",
    "\n",
    "\n",
    "## Link and apply slide widgets \n",
    "perc_training = wg.FloatSlider(min=0.5,max=1,step=.01,description='% of training dataset:')\n",
    "n_neigh = wg.IntSlider(min=1,max=10,step=1,description='n_neighbors parameter:')\n",
    "rand_n = wg.IntSlider(min=1,max=100,step=1,description='n random Knn model iteration:')\n",
    "wg.interactive(multi_knn_model,n_neigh=n_neigh, perc_fig=perc_training, rand_n=rand_n)\n",
    "\n",
    "#display(perc_training, n_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 74,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Building multivariate k-nearest neighbors models: optimizing model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def multi_knn_model_results(n_neigh, perc_fig, rand_n):\n",
    "    \"\"\"\n",
    "    apply knn func \"knn_train_test\" to find best multivariate model for \n",
    "    each random set of features\n",
    "    Inputs:\n",
    "    ________________\n",
    "       - n_neigh: int\n",
    "            n_neighbor parameter in Knn func.\n",
    "       - perc_fig: float\n",
    "            % of dataframe splitting up training and testing set\n",
    "       - rand_n: float\n",
    "            random 'n' number iterations tp run Knn model\n",
    "    Output:\n",
    "    _________________\n",
    "       - list of average of RMSE \n",
    "    \"\"\"\n",
    "    ## create random, nonrepetitive pairs from a list of columns  \n",
    "    result_1 = {}\n",
    "    features_cols_lst = [col for idx, col in enumerate(list(cars_normalized_df.columns)) if col != 'price']\n",
    "    for idx, col in enumerate(features_cols_lst):\n",
    "            x = np.random.choice(features_cols_lst, idx, replace=False)\n",
    "            result_1[idx] = x\n",
    "    res1 = [item for item in result_1.values() if len(item) > 1]\n",
    "            \n",
    "    ## Applying \"knn_train_test\" to find best multivariate Knn model based on random feature selction \n",
    "    ## Iterating thru each multi-col selection \n",
    "    RMSE_total = {}\n",
    "    for i in range(rand_n):\n",
    "        RMSE_RES = {}\n",
    "        for idx,pair in enumerate(res1):\n",
    "            RMSE_RES[len(pair)] = multi_knn_train_test(cars_normalized_df ,pair ,'price',perc_fig ,n_neigh)\n",
    "        RMSE_total[i] = RMSE_RES\n",
    "    lst_rmse = []    \n",
    "    for i_1 in range(len(RMSE_total.keys())):\n",
    "        x = list(list(RMSE_total.values())[i_1].values())\n",
    "        lst_rmse.append(x)\n",
    "    avrg_rmse = [sum(n)/len(n) for n in list(zip(*lst_rmse))]   \n",
    "    avrg_rmse_plt_df = pd.DataFrame(avrg_rmse,columns=['Avrg RMSE'] ,index=list(list(RMSE_total.values())[0]))\n",
    "    return avrg_rmse_plt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 16,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# optimazing \"multi_knn_model_results\" parametrs\n",
    "# 1. n_neighbor parameter\n",
    "%time\n",
    "optimizing_k_niegh_para = list(\n",
    "    itertools.chain(\n",
    "        *[np.mean(multi_knn_model_results(iter_1,0.75,10)) for iter_1 in range(2, 60)]\n",
    "    )\n",
    ")\n",
    "# the range been selcted randomly to be betw(2,125) it can be chnaged !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 43,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# 2.trainin / testing datset set up \n",
    "%time\n",
    "## Find the optimum point where Avrg-RMSE is the lowest\n",
    "optimizing_train_test_para = list(\n",
    "    itertools.chain(\n",
    "        *[np.mean(multi_knn_model_results(5,iter_2,10)) for iter_2 in [((x /.1) / 100) for x in range(1, 10)]]   \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 66,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# 3. Find the best Multi Knn model based on optmizing the prev. parameters\n",
    "%time\n",
    "\n",
    "optimizing_multi_knn_model = list(\n",
    "    itertools.chain(\n",
    "        *[np.mean(multi_knn_model_results(45,.8,iter_3)) for iter_3 in range(1, 50)]\n",
    "    )\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 22,
        "hidden": false,
        "row": 115,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "## Build a visualizations for parametrs\n",
    "fig, axs = plt.subplots(3, figsize=(15,12))\n",
    "\n",
    "##setting up the plot frame / title text color\n",
    "frm_color = 'white'\n",
    "for ax in axs:\n",
    "    ax.tick_params(color=frm_color, labelcolor=frm_color)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(frm_color)\n",
    "        \n",
    "## plotting up the results\n",
    "axs[0].plot(optimizing_k_niegh_para)\n",
    "axs[0].set_title('n_neighbor parameter - Hyperprameter', color=frm_color)\n",
    "axs[0].set_ylabel('AVRG RMSE', color=frm_color)\n",
    "\n",
    "\n",
    "axs[1].plot(optimizing_train_test_para)\n",
    "axs[1].set_title('trainin / testing datset set up ', color=frm_color)\n",
    "axs[1].set_ylabel('AVRG RMSE', color=frm_color)\n",
    "axs[1].set_xlim(xmin=0.1)\n",
    "\n",
    "axs[2].plot(optimizing_multi_knn_model)\n",
    "axs[2].set_title('Best Knn model',  color=frm_color)\n",
    "axs[2].set_ylabel('AVRG RMSE', color=frm_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 78,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Key take away from the multivariate Knn model\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 1,
        "height": 4,
        "hidden": false,
        "row": 51,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Appendix: Add some functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def search_text_google(text_str, lng, stop_val):\n",
    "    \"\"\"\n",
    "    Simple google search func \n",
    "    \"\"\"\n",
    "    for url in search(text_str, tld='com', lang=lng, stop=stop_val):\n",
    "        print(url)\n",
    "\n",
    "def download_data(url):\n",
    "    \"\"\"\n",
    "    Helps retrieving wheather applying request is sucsseful or not with \n",
    "    showing results \n",
    "    \"\"\"\n",
    "    Response = namedtuple('Response', ['data', 'error'])\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except Exception as e:\n",
    "        return Response(data = None , error = e)\n",
    "    if r.status_code == 200:\n",
    "        return Response(data=r, error=None)\n",
    "    else:\n",
    "        return Response(data=None, error=r.reason)\n",
    "\n",
    "def gen_all_features_combinations(df, target_col):\n",
    "    \"\"\"\n",
    "    This func generates (2^n -1) possible combinations for the features list (itertools should be imported)\n",
    "    within df excluding target col.\n",
    "      - df: defined dataframe \n",
    "      - target_col: the target column to be excluded from the main dataframe \n",
    "    \"\"\"\n",
    "    x =[col for idx, col in enumerate(list(df.columns)) if col != target_col]\n",
    "    features_lst = [list(subset) for l in range(0, len(x)+1) for subset in itertools.combinations(x, l)]\n",
    "    return features_lst\n",
    "\n",
    "#(2^n)n >> combination with repetition (itertools.permutations)\n",
    "#2^n >> combination without repetition (itertools.combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 7,
        "height": 4,
        "hidden": false,
        "row": 53,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "##  Multivariate Knn k-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Setting up k-fold for the dataset \n",
    "## Classify dataframe to 'i'th k-fold of training and testing seubset\n",
    "def set_Kfold(kfold_df, k_val):\n",
    "    \"\"\"\n",
    "    generating k-fold to prepare training /testing data subsets\n",
    "    Inputs:\n",
    "    _______________\n",
    "     - df: dataframe \n",
    "         input dataframe\n",
    "     - k_val: int\n",
    "         int value to define a k-fold to seubset dataframe \n",
    "     Output:\n",
    "     ______________\n",
    "     - generates dataframe with \"fold\" column representing k-fold for training/testing subset\n",
    "    \"\"\"\n",
    "    kfold_df['fold'] = 1\n",
    "    start = int(len(kfold_df)/k_val)\n",
    "    rng_vls = [int(x) for x in np.linspace(start=start, stop=len(kfold_df), num=k_val)]\n",
    "    for idx, val in enumerate(rng_vls):\n",
    "        kfold_df['fold'][rng_vls[idx]-start: val] = idx+1\n",
    "    return kfold_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## Apply multi Knn model and validating with k-fold methodology\n",
    "def train_and_validate_kFold(df, Kfold_num, n_neigh, feature_cols, target_cols):\n",
    "    \"\"\"\n",
    "    Multi Knn model with k-fold validation methodology\n",
    "    Inputs:\n",
    "    _______________\n",
    "     - df: dataframe \n",
    "         input dataframe\n",
    "     - kfold_num: int\n",
    "         int value to define a k-fold to seubset dataframe \n",
    "     Output:\n",
    "     ______________\n",
    "     - generates dataframe with \"fold\" column representing k-fold for training/testing subset\n",
    "    \"\"\"\n",
    "    new_kFold_df = set_Kfold(df, Kfold_num)\n",
    "    fold_ids = list(set(new_kFold_df['fold']))\n",
    "    rmse = []\n",
    "    for i in fold_ids:\n",
    "        training_set = new_kFold_df[new_kFold_df['fold']!=i]\n",
    "        testing_set =  new_kFold_df[new_kFold_df['fold']==i]\n",
    "\n",
    "        knn = KNeighborsRegressor(n_neighbors = n_neigh)\n",
    "        fits = knn.fit(training_set[feature_cols], training_set[target_cols])\n",
    "        predicts = knn.predict(testing_set[feature_cols])\n",
    "        iteration_i_rmse = (mean_squared_error(testing_set[target_cols], predicts))**.5\n",
    "        rmse.append(iteration_i_rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## Apply multivariate Knn using cros k-fold methodology\n",
    "def multi_knn_model_kfold(n_neigh, Kfold_num, rand_n):\n",
    "    \"\"\"\n",
    "    apply knn func \"knn_train_test\" to find best multivariate model for \n",
    "    each random set of features\n",
    "    Inputs:\n",
    "    ________________\n",
    "       - n_neigh: int\n",
    "           n_neighbor parameter in Knn func.\n",
    "       - perc_fig: float\n",
    "           % of dataframe splitting up training and testing set\n",
    "       - rand_n: float\n",
    "           random 'n' number iterations tp run Knn model\n",
    "   Outputs:\n",
    "   _________________\n",
    "       - list of average RMSE\n",
    "    \"\"\"\n",
    "    ## create random, nonrepetitive pairs from a list of columns\n",
    "    #for iteration in range(rand_n):\n",
    "        #multi_col_rnd_selection = {idx:np.random.choice(cars_normalized_df.columns, idx, replace=False) for idx, col in enumerate(cars_normalized_df.columns)}\n",
    "        #multi_rnd_selection_excpt_0_1 = [item for item in multi_col_rnd_selection.values() if len(item) > 1]\n",
    "    ###################### New set up#######################   \n",
    "    result_1 = {}\n",
    "    features_cols_lst = [col for idx, col in enumerate(list(cars_normalized_df.columns)) if col != 'price']\n",
    "    for idx, col in enumerate(features_cols_lst):\n",
    "            x = np.random.choice(features_cols_lst, idx, replace=False)\n",
    "            result_1[idx] = x\n",
    "    res1 = [item for item in result_1.values() if len(item) > 1]\n",
    "            \n",
    "    ## Applying \"knn_train_test\" to find best multivariate Knn model based on random feature selction \n",
    "    ## Iterating thru each multi-col selection \n",
    "    RMSE_total = {}\n",
    "    for i in range(rand_n):\n",
    "        RMSE_RES = {}\n",
    "        for idx,pair in enumerate(res1):\n",
    "            Kfold_rmse = train_and_validate_kFold(cars_normalized_df, Kfold_num, n_neigh, pair,'price')\n",
    "            RMSE_RES[len(pair)] = np.mean(Kfold_rmse)\n",
    "                                    #multi_knn_train_test(cars_normalized_df ,pair ,'price',perc_fig ,n_neigh)\n",
    "        RMSE_total[i] = RMSE_RES\n",
    "    lst_rmse = []    \n",
    "    for i_1 in range(len(RMSE_total.keys())):\n",
    "        x = list(list(RMSE_total.values())[i_1].values())\n",
    "        lst_rmse.append(x)\n",
    "    avrg_rmse = [sum(n)/len(n) for n in list(zip(*lst_rmse))]   \n",
    "    avrg_rmse_plt_df = pd.DataFrame(avrg_rmse, columns=['Avrg RMSE'] ,index=list(list(RMSE_total.values())[0]))\n",
    "    \n",
    "    return avrg_rmse_plt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Knn model interactivity \n",
    "def Kfold_iter(n_neigh, min_rng, max_rng, n_rnd):\n",
    "    \"\"\"\n",
    "    Apply multi_knn_model_kfold function to iterate thru a range of different kfolds\n",
    "    Imputs:\n",
    "    ____________\n",
    "     - n_neigh: int\n",
    "         n_neighbor parameter for Knn model\n",
    "     - min_rng: int\n",
    "         min value of a range \n",
    "     - max_rng: int\n",
    "         max value of a range \n",
    "     - min_rng: int\n",
    "         n range for random iterations\n",
    "    \"\"\"\n",
    "    avrg_rmse_kfolg = []\n",
    "    for i in range(min_rng, max_rng):\n",
    "        d = multi_knn_model_kfold(n_neigh, i, n_rnd)\n",
    "        avrg_rmse_kfolg.append(d['Avrg RMSE'].mean())\n",
    "        \n",
    "    #Set up the plot figures and style\n",
    "    ax.clear()\n",
    "    ax.bar([(idx+1) for idx, val in enumerate(avrg_rmse_kfolg)], avrg_rmse_kfolg)\n",
    "    frm_color = 'white'\n",
    "    ax.tick_params(color=frm_color, labelcolor=frm_color)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(frm_color)\n",
    "    plt.style.use('seaborn')\n",
    "    plt.title('Multi Knn model with Kfold performance / Avrg-RMSE', color='white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 10,
        "hidden": false,
        "row": 4,
        "width": 7
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## Apply Multivariate Knn with kfold methodology\n",
    "fig, ax = plt.subplots(1, figsize=(12,5))\n",
    "Kfold_iter(10, 2, 11, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": true,
        "row": 11,
        "width": 12
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 82,
        "width": 12
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
